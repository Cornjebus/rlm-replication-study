<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>RLM Replication Study - OOLONG Results</title>
    <style>
        :root {
            --primary: #2563eb;
            --secondary: #64748b;
            --success: #10b981;
            --warning: #f59e0b;
            --bg: #f8fafc;
            --card-bg: #ffffff;
            --text: #1e293b;
            --text-muted: #64748b;
            --border: #e2e8f0;
        }

        * { margin: 0; padding: 0; box-sizing: border-box; }

        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
            background: var(--bg);
            color: var(--text);
            line-height: 1.6;
        }

        .container {
            max-width: 900px;
            margin: 0 auto;
            padding: 2rem;
        }

        header {
            text-align: center;
            padding: 2.5rem 0;
            background: #1e293b;
            color: white;
            margin-bottom: 2rem;
        }

        header h1 { font-size: 2rem; margin-bottom: 0.5rem; }
        header .subtitle { opacity: 0.8; }
        .meta { display: flex; justify-content: center; gap: 2rem; margin-top: 1rem; font-size: 0.85rem; opacity: 0.7; }

        section {
            background: var(--card-bg);
            border-radius: 10px;
            padding: 1.75rem;
            margin-bottom: 1.25rem;
            box-shadow: 0 1px 3px rgba(0,0,0,0.08);
        }

        section h2 {
            color: var(--primary);
            margin-bottom: 1rem;
            font-size: 1.25rem;
            display: flex;
            align-items: center;
            gap: 0.5rem;
        }

        .num {
            background: var(--primary);
            color: white;
            width: 26px;
            height: 26px;
            border-radius: 50%;
            display: inline-flex;
            align-items: center;
            justify-content: center;
            font-size: 0.8rem;
            font-weight: 600;
        }

        table { width: 100%; border-collapse: collapse; margin: 1rem 0; }
        th, td { padding: 0.6rem 0.75rem; text-align: left; border-bottom: 1px solid var(--border); }
        th { background: var(--bg); font-weight: 600; color: var(--secondary); font-size: 0.8rem; text-transform: uppercase; }

        blockquote {
            border-left: 3px solid var(--secondary);
            padding-left: 1rem;
            margin: 1rem 0;
            color: var(--text-muted);
            font-style: italic;
            font-size: 0.95rem;
        }

        pre {
            background: #1e293b;
            color: #e2e8f0;
            padding: 1rem;
            border-radius: 6px;
            overflow-x: auto;
            font-size: 0.85rem;
        }

        code {
            background: #1e293b;
            color: #e2e8f0;
            padding: 0.15rem 0.35rem;
            border-radius: 3px;
            font-size: 0.9em;
        }

        .results-chart { margin: 1.5rem 0; }

        .bar-row {
            display: flex;
            align-items: center;
            margin-bottom: 0.6rem;
        }

        .bar-label { width: 150px; font-weight: 500; font-size: 0.9rem; }

        .bar-container {
            flex: 1;
            background: var(--border);
            border-radius: 4px;
            height: 26px;
            margin-right: 0.75rem;
            overflow: hidden;
        }

        .bar {
            height: 100%;
            display: flex;
            align-items: center;
            justify-content: flex-end;
            padding-right: 0.5rem;
            color: white;
            font-weight: 500;
            font-size: 0.85rem;
        }

        .bar.rlm { background: var(--secondary); width: 56.5%; }
        .bar.hybrid { background: var(--warning); width: 59.59%; }
        .bar.pure { background: var(--success); width: 73.24%; }

        .bar-calls { width: 90px; text-align: right; color: var(--text-muted); font-size: 0.85rem; }

        .callout {
            padding: 0.75rem 1rem;
            border-radius: 6px;
            margin: 1rem 0;
            background: #f1f5f9;
            border-left: 3px solid var(--secondary);
            font-size: 0.95rem;
        }

        .pipeline {
            display: flex;
            align-items: center;
            gap: 0.5rem;
            margin: 1rem 0;
            flex-wrap: wrap;
        }

        .step {
            background: var(--bg);
            padding: 0.5rem 1rem;
            border-radius: 6px;
            font-size: 0.9rem;
        }

        .arrow { color: var(--secondary); }

        ul { padding-left: 1.25rem; }
        li { margin: 0.3rem 0; }

        footer {
            text-align: center;
            padding: 1.5rem;
            color: var(--text-muted);
            font-size: 0.85rem;
        }

        footer a { color: var(--primary); }
    </style>
</head>
<body>
    <header>
        <div class="container">
            <h1>RLM Replication Study</h1>
            <p class="subtitle">OOLONG Benchmark Results</p>
            <div class="meta">
                <span>January 2025</span>
                <span>arXiv:2512.24601</span>
                <span>trec_coarse (n=250)</span>
            </div>
        </div>
    </header>

    <div class="container">

        <!-- Summary -->
        <section>
            <h2><span class="num">1</span> Summary</h2>
            <p>The RLM paper proposes recursive language models to handle long contexts and mitigate "context rot." They show RLM improves GPT-5 from 44% to 56.5% on OOLONG.</p>

            <p style="margin-top: 1rem;">We tested an alternative: per-record classification with deterministic aggregation.</p>

            <div class="results-chart">
                <div class="bar-row">
                    <div class="bar-label">GPT-5 Base (paper)</div>
                    <div class="bar-container"><div class="bar" style="background:#94a3b8;width:44%">44%</div></div>
                    <div class="bar-calls"></div>
                </div>
                <div class="bar-row">
                    <div class="bar-label">GPT-5 RLM (paper)</div>
                    <div class="bar-container"><div class="bar rlm">56.5%</div></div>
                    <div class="bar-calls"></div>
                </div>
                <div class="bar-row">
                    <div class="bar-label">Our Hybrid</div>
                    <div class="bar-container"><div class="bar hybrid">59.6%</div></div>
                    <div class="bar-calls">~580 calls</div>
                </div>
                <div class="bar-row">
                    <div class="bar-label">Our Pure GPT-5</div>
                    <div class="bar-container"><div class="bar pure">73.2%</div></div>
                    <div class="bar-calls">1,900 calls</div>
                </div>
            </div>

            <p>Our approach outscored both their baseline and their RLM.</p>
        </section>

        <!-- RLM Claims -->
        <section>
            <h2><span class="num">2</span> RLM Paper Results</h2>
            <p>From the paper on OOLONG trec_coarse:</p>
            <table>
                <tr><th>Method</th><th>Score</th></tr>
                <tr><td>GPT-5 Base</td><td>44.00%</td></tr>
                <tr><td>GPT-5 RLM</td><td>56.50%</td></tr>
            </table>
            <p style="margin-top:0.75rem">RLM improved their baseline by +12.5 points.</p>
            <p style="margin-top:0.5rem;color:var(--text-muted);font-size:0.9rem"><strong>On API calls:</strong> Paper notes ~10 sub-calls for simple tasks, "hundreds to thousands" for complex. Exact OOLONG counts not specified.</p>
        </section>

        <!-- Our Approach -->
        <section>
            <h2><span class="num">3</span> Our Approach</h2>
            <p>OOLONG aggregation queries have a specific structure:</p>
            <ul>
                <li>Context contains 100+ independent records</li>
                <li>Query asks for counts or frequency comparisons</li>
                <li>Records can be classified individually</li>
            </ul>

            <div class="pipeline">
                <div class="step">Parse records</div>
                <span class="arrow">→</span>
                <div class="step">Classify each (~50 tokens)</div>
                <span class="arrow">→</span>
                <div class="step">Counter().most_common()</div>
            </div>

            <p>No recursion needed. Counting is deterministic.</p>
        </section>

        <!-- Methodology -->
        <section>
            <h2><span class="num">4</span> Methodology</h2>
            <table>
                <tr><th>Aspect</th><th>RLM Paper</th><th>Our Study</th></tr>
                <tr><td>Model</td><td>GPT-5</td><td>gpt-5-chat-latest</td></tr>
                <tr><td>Dataset</td><td>trec_coarse</td><td>trec_coarse</td></tr>
                <tr><td>Metric</td><td>OOLONG score</td><td>OOLONG score</td></tr>
                <tr><td>Examples</td><td>250</td><td>250</td></tr>
            </table>

            <h3 style="margin-top: 1.25rem; font-size: 1rem;">Hybrid Variant</h3>
            <p>Cost-optimized version using heuristics before LLM:</p>
            <table>
                <tr><th>Layer</th><th>Records</th><th>Cost</th></tr>
                <tr><td>Keyword matching</td><td>60.3%</td><td>Free</td></tr>
                <tr><td>Embedding similarity</td><td>7.4%</td><td>Local</td></tr>
                <tr><td>GPT-5 API</td><td>32.3%</td><td>Paid</td></tr>
            </table>
        </section>

        <!-- Results -->
        <section>
            <h2><span class="num">5</span> Results</h2>
            <table>
                <tr><th>Method</th><th>Score</th><th>Exact Match</th><th>Calls</th></tr>
                <tr><td>GPT-5 Base (paper)</td><td>44.00%</td><td>—</td><td>—</td></tr>
                <tr><td>GPT-5 RLM (paper)</td><td>56.50%</td><td>—</td><td>~10-1000s/query*</td></tr>
                <tr><td>Our Pure GPT-5</td><td><strong>73.24%</strong></td><td>63.60%</td><td>1,900 total</td></tr>
                <tr><td>Our Hybrid GPT-5</td><td>59.59%</td><td>49.20%</td><td>~580 total</td></tr>
            </table>
            <p style="font-size:0.85rem;color:var(--text-muted);margin-top:0.5rem">*Paper notes ~10 sub-calls for simple tasks, "hundreds to thousands" for complex. Exact OOLONG counts not reported.</p>

            <h3 style="margin-top: 1.25rem; font-size: 1rem;">By Task Type</h3>
            <table>
                <tr><th>Task</th><th>Score</th><th>N</th></tr>
                <tr><td>SECOND_MOST_FREQ</td><td>100.0%</td><td>4</td></tr>
                <tr><td>RELATIVE_FREQ</td><td>79.3%</td><td>140</td></tr>
                <tr><td>LEAST_FREQ</td><td>68.8%</td><td>16</td></tr>
                <tr><td>NUMERIC_ONE_CLASS</td><td>64.8%</td><td>65</td></tr>
                <tr><td>MOST_FREQ</td><td>60.0%</td><td>25</td></tr>
            </table>
        </section>

        <!-- Limitations -->
        <section>
            <h2><span class="num">6</span> Limitations</h2>
            <table>
                <tr><th>Limitation</th><th>Note</th></tr>
                <tr><td>Single benchmark</td><td>Only OOLONG trec_coarse (n=250)</td></tr>
                <tr><td>Single split</td><td>Did not test other OOLONG datasets</td></tr>
                <tr><td>Aggregation only</td><td>Did not test BrowseComp or other tasks</td></tr>
            </table>
            <p style="margin-top: 0.75rem;">This is one benchmark. RLM may perform differently on other tasks.</p>
        </section>

        <!-- Reproduce -->
        <section>
            <h2><span class="num">7</span> Reproduce</h2>
            <pre>export OPENAI_API_KEY="sk-..."

# Pure GPT-5
python3 run_oolong_gpt5.py --dataset trec_coarse

# Hybrid
python3 run_oolong_hybrid_gpt5.py --dataset trec_coarse</pre>

            <p style="margin-top: 1rem;">Results saved to <code>benchmark_data/</code></p>
        </section>

        <!-- Conclusion -->
        <section>
            <h2><span class="num">8</span> Conclusion</h2>
            <p>On OOLONG trec_coarse: GPT-5 Base 44% → GPT-5 RLM 56.5% → Our approach 73.24%</p>
        </section>

    </div>

    <footer>
        <p>January 2025 · GPT-5 · OOLONG trec_coarse (n=250)</p>
        <p>Reference: Zhang et al. "Recursive Language Models" <a href="https://arxiv.org/abs/2512.24601">arXiv:2512.24601</a></p>
    </footer>

</body>
</html>
